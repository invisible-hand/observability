{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "506943c8-465f-4cf3-8410-2d1690b46327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dccaff2b-302a-485e-9e27-a4e30925186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from openinference.instrumentation import TracerProvider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "067e5f05-25aa-4391-9647-5392c8e1966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the OpenAI client\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8901a1b2-d34e-4d23-91b2-329a2f4ac7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"az-tracing-agent-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05dd29d4-d09a-4f3b-b4d4-6a8d2c43dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phoenix_endpoint():\n",
    "    load_dotenv()\n",
    "    phoenix_endpoint = os.getenv(\"PHOENIX_COLLECTOR_ENDPOINT\")\n",
    "    return phoenix_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7f1fddc6-b811-4682-a250-8af58cb940ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: az-tracing-agent-2\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: https://app.phoenix.arize.com/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {'api_key': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(project_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e59dc53c-a748-4076-8135-ed0fd63e0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "# OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc105e71-7a74-4a26-9b5c-6fe8961f5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke 1:\n",
      "Why was the math book sad? Because it had too many problems.\n",
      "\n",
      "Joke 2:\n",
      "Why couldn't the leopard play hide and seek?\n",
      "\n",
      "Because he was always spotted!\n",
      "\n",
      "Joke 3:\n",
      "Sure! Why couldn't the bicycle stand up by itself? Because it was two tired!\n",
      "\n",
      "Joke 4:\n",
      "Sure, here's a joke for you: Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "Joke 5:\n",
      "Sure! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "Joke 6:\n",
      "Why couldn't the bicycle stand up by itself? Because it was two tired!\n",
      "\n",
      "Joke 7:\n",
      "Why did the math book look sad? Because it had too many problems.\n",
      "\n",
      "Joke 8:\n",
      "Sure, here's one for you: Why was the math book sad?\n",
      "\n",
      "Because it had too many problems.\n",
      "\n",
      "Joke 9:\n",
      "Why did the math book look sad? Because it had too many problems.\n",
      "\n",
      "Joke 10:\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "Joke 11:\n",
      "Sure, here you go: Why couldn't the bicycle stand up by itself? Because it was two tired!\n",
      "\n",
      "Joke 12:\n",
      "Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "Joke 13:\n",
      "Sure! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "Joke 14:\n",
      "Sure! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "Joke 15:\n",
      "Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "Generated 15 jokes and tracked them in Phoenix.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Function to generate a joke\n",
    "def generate_joke():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates jokes.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "        ],\n",
    "    )\n",
    "    joke = response.choices[0].message.content\n",
    "    return joke\n",
    "\n",
    "\n",
    "# Generate 5 different jokes\n",
    "jokes = []\n",
    "for _ in range(15):\n",
    "    joke = generate_joke()\n",
    "    jokes.append(joke)\n",
    "    print(f\"Joke {len(jokes)}:\\n{joke}\\n\")\n",
    "\n",
    "print(f\"Generated {len(jokes)} jokes and tracked them in Phoenix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39652ece-3998-4950-b29b-33b6a0010bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey/miniconda3/envs/new_env/lib/python3.11/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (8.19.0) and client (8.20.0) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>span_kind</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>status_code</th>\n",
       "      <th>status_message</th>\n",
       "      <th>events</th>\n",
       "      <th>context.span_id</th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>...</th>\n",
       "      <th>attributes.output.mime_type</th>\n",
       "      <th>attributes.llm.output_messages</th>\n",
       "      <th>attributes.openinference.span.kind</th>\n",
       "      <th>attributes.llm.token_count.prompt</th>\n",
       "      <th>attributes.input.mime_type</th>\n",
       "      <th>attributes.output.value</th>\n",
       "      <th>attributes.llm.provider</th>\n",
       "      <th>attributes.llm.token_count.completion</th>\n",
       "      <th>attributes.llm.token_count.total</th>\n",
       "      <th>attributes.llm.model_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44280d11680f19eb</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-02 04:07:34.926183+00:00</td>\n",
       "      <td>2025-04-02 04:07:35.397944+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>44280d11680f19eb</td>\n",
       "      <td>c3ff93cbf5f50a33e041bd9838a530a1</td>\n",
       "      <td>...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.role': 'assistant', 'message.conten...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>25</td>\n",
       "      <td>application/json</td>\n",
       "      <td>{\"id\":\"chatcmpl-BHjfz72mEdlfW9WVShYRhXJjQuln7\"...</td>\n",
       "      <td>openai</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f789482107cb326e</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-02 04:07:35.515984+00:00</td>\n",
       "      <td>2025-04-02 04:07:35.925719+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>f789482107cb326e</td>\n",
       "      <td>fb96e4cbd10ed84c06790567da3e6ff2</td>\n",
       "      <td>...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.role': 'assistant', 'message.conten...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>25</td>\n",
       "      <td>application/json</td>\n",
       "      <td>{\"id\":\"chatcmpl-BHjfzfv8kJvxBee3o33xypLfkmHjV\"...</td>\n",
       "      <td>openai</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b68673e8a78d218a</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-02 04:07:36.021262+00:00</td>\n",
       "      <td>2025-04-02 04:07:36.409034+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>b68673e8a78d218a</td>\n",
       "      <td>0b08590ef9f7c3e0891572e0250e4126</td>\n",
       "      <td>...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.role': 'assistant', 'message.conten...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>25</td>\n",
       "      <td>application/json</td>\n",
       "      <td>{\"id\":\"chatcmpl-BHjg0ALFHbiGzZoBl81cOn3JzJ9ZO\"...</td>\n",
       "      <td>openai</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2aa6dfbd70a499e0</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-02 04:07:36.504782+00:00</td>\n",
       "      <td>2025-04-02 04:07:36.993866+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>2aa6dfbd70a499e0</td>\n",
       "      <td>383e34c8682fffbb12a575e719aff3c2</td>\n",
       "      <td>...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.role': 'assistant', 'message.conten...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>25</td>\n",
       "      <td>application/json</td>\n",
       "      <td>{\"id\":\"chatcmpl-BHjg0RE2T5aHEPe0K6nUHBX4gm5YY\"...</td>\n",
       "      <td>openai</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d88ca74b8d9d4fa4</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-02 04:07:37.071929+00:00</td>\n",
       "      <td>2025-04-02 04:07:37.506180+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>d88ca74b8d9d4fa4</td>\n",
       "      <td>a368da7a2e34f0d288fdbe77bd6d104b</td>\n",
       "      <td>...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>[{'message.role': 'assistant', 'message.conten...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>25</td>\n",
       "      <td>application/json</td>\n",
       "      <td>{\"id\":\"chatcmpl-BHjg15V6drE6TQbxFqBhll8cFKoGQ\"...</td>\n",
       "      <td>openai</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name span_kind parent_id  \\\n",
       "context.span_id                                        \n",
       "44280d11680f19eb  ChatCompletion       LLM      None   \n",
       "f789482107cb326e  ChatCompletion       LLM      None   \n",
       "b68673e8a78d218a  ChatCompletion       LLM      None   \n",
       "2aa6dfbd70a499e0  ChatCompletion       LLM      None   \n",
       "d88ca74b8d9d4fa4  ChatCompletion       LLM      None   \n",
       "\n",
       "                                       start_time  \\\n",
       "context.span_id                                     \n",
       "44280d11680f19eb 2025-04-02 04:07:34.926183+00:00   \n",
       "f789482107cb326e 2025-04-02 04:07:35.515984+00:00   \n",
       "b68673e8a78d218a 2025-04-02 04:07:36.021262+00:00   \n",
       "2aa6dfbd70a499e0 2025-04-02 04:07:36.504782+00:00   \n",
       "d88ca74b8d9d4fa4 2025-04-02 04:07:37.071929+00:00   \n",
       "\n",
       "                                         end_time status_code status_message  \\\n",
       "context.span_id                                                                \n",
       "44280d11680f19eb 2025-04-02 04:07:35.397944+00:00          OK                  \n",
       "f789482107cb326e 2025-04-02 04:07:35.925719+00:00          OK                  \n",
       "b68673e8a78d218a 2025-04-02 04:07:36.409034+00:00          OK                  \n",
       "2aa6dfbd70a499e0 2025-04-02 04:07:36.993866+00:00          OK                  \n",
       "d88ca74b8d9d4fa4 2025-04-02 04:07:37.506180+00:00          OK                  \n",
       "\n",
       "                 events   context.span_id                  context.trace_id  \\\n",
       "context.span_id                                                               \n",
       "44280d11680f19eb     []  44280d11680f19eb  c3ff93cbf5f50a33e041bd9838a530a1   \n",
       "f789482107cb326e     []  f789482107cb326e  fb96e4cbd10ed84c06790567da3e6ff2   \n",
       "b68673e8a78d218a     []  b68673e8a78d218a  0b08590ef9f7c3e0891572e0250e4126   \n",
       "2aa6dfbd70a499e0     []  2aa6dfbd70a499e0  383e34c8682fffbb12a575e719aff3c2   \n",
       "d88ca74b8d9d4fa4     []  d88ca74b8d9d4fa4  a368da7a2e34f0d288fdbe77bd6d104b   \n",
       "\n",
       "                  ... attributes.output.mime_type  \\\n",
       "context.span_id   ...                               \n",
       "44280d11680f19eb  ...            application/json   \n",
       "f789482107cb326e  ...            application/json   \n",
       "b68673e8a78d218a  ...            application/json   \n",
       "2aa6dfbd70a499e0  ...            application/json   \n",
       "d88ca74b8d9d4fa4  ...            application/json   \n",
       "\n",
       "                                     attributes.llm.output_messages  \\\n",
       "context.span_id                                                       \n",
       "44280d11680f19eb  [{'message.role': 'assistant', 'message.conten...   \n",
       "f789482107cb326e  [{'message.role': 'assistant', 'message.conten...   \n",
       "b68673e8a78d218a  [{'message.role': 'assistant', 'message.conten...   \n",
       "2aa6dfbd70a499e0  [{'message.role': 'assistant', 'message.conten...   \n",
       "d88ca74b8d9d4fa4  [{'message.role': 'assistant', 'message.conten...   \n",
       "\n",
       "                 attributes.openinference.span.kind  \\\n",
       "context.span_id                                       \n",
       "44280d11680f19eb                                LLM   \n",
       "f789482107cb326e                                LLM   \n",
       "b68673e8a78d218a                                LLM   \n",
       "2aa6dfbd70a499e0                                LLM   \n",
       "d88ca74b8d9d4fa4                                LLM   \n",
       "\n",
       "                 attributes.llm.token_count.prompt attributes.input.mime_type  \\\n",
       "context.span_id                                                                 \n",
       "44280d11680f19eb                                25           application/json   \n",
       "f789482107cb326e                                25           application/json   \n",
       "b68673e8a78d218a                                25           application/json   \n",
       "2aa6dfbd70a499e0                                25           application/json   \n",
       "d88ca74b8d9d4fa4                                25           application/json   \n",
       "\n",
       "                                            attributes.output.value  \\\n",
       "context.span_id                                                       \n",
       "44280d11680f19eb  {\"id\":\"chatcmpl-BHjfz72mEdlfW9WVShYRhXJjQuln7\"...   \n",
       "f789482107cb326e  {\"id\":\"chatcmpl-BHjfzfv8kJvxBee3o33xypLfkmHjV\"...   \n",
       "b68673e8a78d218a  {\"id\":\"chatcmpl-BHjg0ALFHbiGzZoBl81cOn3JzJ9ZO\"...   \n",
       "2aa6dfbd70a499e0  {\"id\":\"chatcmpl-BHjg0RE2T5aHEPe0K6nUHBX4gm5YY\"...   \n",
       "d88ca74b8d9d4fa4  {\"id\":\"chatcmpl-BHjg15V6drE6TQbxFqBhll8cFKoGQ\"...   \n",
       "\n",
       "                 attributes.llm.provider  \\\n",
       "context.span_id                            \n",
       "44280d11680f19eb                  openai   \n",
       "f789482107cb326e                  openai   \n",
       "b68673e8a78d218a                  openai   \n",
       "2aa6dfbd70a499e0                  openai   \n",
       "d88ca74b8d9d4fa4                  openai   \n",
       "\n",
       "                  attributes.llm.token_count.completion  \\\n",
       "context.span_id                                           \n",
       "44280d11680f19eb                                     17   \n",
       "f789482107cb326e                                     16   \n",
       "b68673e8a78d218a                                     17   \n",
       "2aa6dfbd70a499e0                                     15   \n",
       "d88ca74b8d9d4fa4                                     18   \n",
       "\n",
       "                 attributes.llm.token_count.total attributes.llm.model_name  \n",
       "context.span_id                                                              \n",
       "44280d11680f19eb                               42        gpt-3.5-turbo-0125  \n",
       "f789482107cb326e                               41        gpt-3.5-turbo-0125  \n",
       "b68673e8a78d218a                               42        gpt-3.5-turbo-0125  \n",
       "2aa6dfbd70a499e0                               40        gpt-3.5-turbo-0125  \n",
       "d88ca74b8d9d4fa4                               43        gpt-3.5-turbo-0125  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import phoenix as px\n",
    "\n",
    "spans_df = px.Client().get_spans_dataframe(project_name=\"evaluating_traces_quickstart\")\n",
    "spans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "536fc9af-5bde-44d5-8659-38c4f3947489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with selected columns\n",
    "eval_df = spans_df[[\"context.span_id\", \"attributes.llm.output_messages\"]].copy()\n",
    "eval_df.set_index(\"context.span_id\", inplace=True)\n",
    "\n",
    "unique_jokes = set()\n",
    "\n",
    "def is_duplicate(joke_data):\n",
    "    # Extract the joke text from the first message in the list\n",
    "    joke = joke_data[0][\"message.content\"]\n",
    "    if joke in unique_jokes:\n",
    "        return True\n",
    "    else:\n",
    "        unique_jokes.add(joke)\n",
    "        return False\n",
    "\n",
    "eval_df[\"label\"] = eval_df[\"attributes.llm.output_messages\"].apply(is_duplicate).astype(int)\n",
    "\n",
    "eval_df[\"score\"] = 1 - eval_df[\"label\"]\n",
    "\n",
    "# Clear the unique_jokes set so that re-running the cell won't accumulate past values.\n",
    "unique_jokes.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28411b3f-b4e7-4490-b727-1bf786754318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['attributes.llm.output_messages', 'label', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(eval_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38194cdf-6e74-4aec-bd4a-c774dcce2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"score\"] = eval_df[\"score\"].astype(int)\n",
    "eval_df[\"label\"] = eval_df[\"label\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1b92ebd-5807-4497-9c65-91db357720fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey/miniconda3/envs/new_env/lib/python3.11/site-packages/phoenix/utilities/client.py:60: UserWarning: The Phoenix server (8.19.0) and client (8.20.0) versions are mismatched and may have compatibility issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(SpanEvaluations(eval_name=\"Duplicate\", dataframe=eval_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bab1b3-0c13-421b-a1e3-3adf9cf7fa55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894d6a7-31cb-4359-bdeb-3c96621ada7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4eedd-d5ad-4d82-8097-d01591c8f822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d74fa-23a3-479c-b8a7-d502dec9ec97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2401df9-9871-4790-bfd2-73e6bb429d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489bf31-dc11-4d0c-9d25-a91c6e07ea88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f9b9f-3ae0-4af1-8a2f-08e75b468188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
